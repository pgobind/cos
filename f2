'javaSparkContext' threw exception with message: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x157853da) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x157853da


actory method 'javaSparkContext' threw exception with message: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x157853da) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x157853da

annot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x157853da

:"Failed to detect a valid hadoop home


{"@timestamp":"2023-05-12T16:25:18.932Z","@version":"1","message":"Failed to detect a valid hadoop home directory","logger_name":"org.apache.hadoop.util.Shell","thread_name":"main","level":"DEBUG","level_value":10000,"stack_trace":"java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\n\tat org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1712)\n\tat org.apache.hadoop.security.SecurityUtil.setConfigurationInternal(SecurityUtil.java:99)\n\tat org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:88)\n\tat org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:312)\n\tat org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:300)\n\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:575)\n\tat org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2583)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2583)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:321)\n\tat


"Class not found so assuming code is running on a pre-Java 19 JVM","logger_name":"org.apache.tomcat.util.compat.Jre19Compat","thread_name":"main","level":"DEBUG","level_value":10000,"stack_trace":"java.lang.ClassNotFoundException: java.lang.WrongThreadException\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:587)\n\tat org.springframework.boot.loader.LaunchedURLClassLoader.loadClass(LaunchedURLClassLoader.java:133)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat org.apache.tomcat.util.compat.Jre19Compat.<clinit>(Jre19Compat.java:37)\n\tat


Failed to instantiate [org.apache.spark.api.java.JavaSparkContext]: Factory method 'javaSparkContext' threw exception with message: javax/servlet/Servlet
