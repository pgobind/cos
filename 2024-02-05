import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class SparkSQLInserts {

    public static void main(String[] args) {
        SparkSession spark = SparkSession.builder()
                .appName("Spark SQL Inserts")
                .enableHiveSupport() // Needed if you're inserting into Hive tables
                .getOrCreate();

        // Assuming fc_gmi_payables_data, sca_gl_xref, org_ou_xref are already defined DataFrames
        // Dataset<Row> fcGmiPayablesData = ...;
        // Dataset<Row> scaGlXref = ...;
        // Dataset<Row> orgOuXref = ...;

        // Register the DataFrames as temporary views
        fcGmiPayablesData.createOrReplaceTempView("fc_gmi_payables_data");
        scaGlXref.createOrReplaceTempView("sca_gl_xref");
        orgOuXref.createOrReplaceTempView("org_ou_xref");

        // First INSERT INTO operation
        String sqlText1 = 
            "INSERT INTO payables_postings " +
            "SELECT " +
            "   CAST(p.id_le AS INT), " +
            "   CAST(p.id_ou AS INT), " +
            "   p.id_cy_iso, " +
            "   CAST(CAST(p.id_gl_acct AS NUMERIC) AS STRING) AS id_gl_acct, " +
            "   SUM(p.am_posting) * -1 + 1 AS gmi_post_minus_1_5_PV " +
            "FROM " +
            "   fc_gmi_payables_data p " +
            "INNER JOIN sca_gl_xref s ON p.id_gl_acct = s.id_gl_acct " +
            "INNER JOIN org_ou_xref o ON p.id_ou = o.id_ou " +
            "   AND p.id_le = o.id_le " +
            "   AND p.id_merit_le = o.id_merit_le " +
            "WHERE " +
            "   p.pn_ulq = 'n' " +
            "   AND p.dt_load < 'Dategemi' " + // Replace 'Dategemi' with the actual date
            "GROUP BY " +
            "   p.id_le, " +
            "   p.id_ou, " +
            "   p.id_cy_iso, " +
            "   p.id_gl_acct";

        // Execute the first SQL query
        spark.sql(sqlText1);

        // Second INSERT INTO operation (Please adjust the SQL as per your second operation's logic)
        String sqlText2 = 
            "INSERT INTO another_table " + // Replace with your actual table name
            "SELECT " +
            "   /* Your select statement based on the second query logic */";

        // Execute the second SQL query
        spark.sql(sqlText2);

        spark.stop();
    }
}
