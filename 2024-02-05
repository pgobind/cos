import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class SparkSQLUpdate {

    public static void main(String[] args) {
        SparkSession spark = SparkSession.builder()
                .appName("Spark SQL Update")
                .getOrCreate();

        // Assuming fc_daily_payables_data is your initial DataFrame
        // Dataset<Row> fcDailyPayablesData = ...;

        // Register the DataFrame as a temporary view
        fcDailyPayablesData.createOrReplaceTempView("fc_daily_payables_rec");

        // Define the SQL query for the update
        String sqlUpdate = 
            "SELECT " +
            "   f1.*, " +
            "   COALESCE(f2.gmi_post_d1, f1.gmi_post_d2) as gmi_post_d2, " +
            "   COALESCE(f2.gmi_post_d2, f1.gmi_post_d3) as gmi_post_d3 " +
            "FROM " +
            "   fc_daily_payables_rec f1 " +
            "LEFT JOIN " +
            "   fc_daily_payables_rec f2 " +
            "ON " +
            "   f1.id_le = f2.id_le " +
            "   AND f1.id_ou = f2.id_ou " +
            "   AND f1.id_gmi_cust = f2.id_gmi_cust " +
            "   AND f1.id_cy_iso = f2.id_cy_iso " +
            "   AND f1.dt_load = 'Dategemi' " + // Replace 'Dategemi' with the actual date
            "   AND f2.dt_load = 'Dt_day2' " +  // Replace 'Dt_day2' with the actual date
            "   AND TRIM(f1.id_gl_acc) = TRIM(f2.id_gl_acc)";

        // Execute the update SQL query
        Dataset<Row> updatedResult = spark.sql(sqlUpdate);

        // Show the result or write it to storage
        updatedResult.show();

        // If you need to update the actual stored data, you would then write this DataFrame to overwrite the original data
        // updatedResult.write().mode("overwrite").saveAsTable("fc_daily_payables_rec");

        spark.stop();
    }
}
