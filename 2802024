from pyspark.sql import SparkSession
from pyspark.sql.functions import coalesce, trim, col, lit

# Initialize Spark session
spark = SparkSession.builder.appName("SQL to Spark Conversion").getOrCreate()

# Assuming the DataFrames have already been created and are named as follows:
# rec_pl_3way_mtd_posting_sum_df and rec_pl_3way_acct_linkage_df
# Also assuming that you have registered these DataFrames as temporary views
rec_pl_3way_mtd_posting_sum_df.createOrReplaceTempView("rec_pl_3way_mtd_posting_sum")
rec_pl_3way_acct_linkage_df.createOrReplaceTempView("rec_pl_3way_acct_linkage")

# Write the Spark SQL equivalent of the update statement
spark.sql("""
    SELECT
        p.*,
        CASE
            WHEN COALESCE(TRIM(p.id_gl_acct), '') = COALESCE(TRIM(l.id_gl_acct), '') AND p.dt_load = @recdate
            THEN l.gl_acct_type
            ELSE p.instrmnt_type
        END AS instrmnt_type
    FROM
        rec_pl_3way_mtd_posting_sum p
    LEFT JOIN
        rec_pl_3way_acct_linkage l
    ON
        COALESCE(TRIM(p.id_gl_acct), '') = COALESCE(TRIM(l.id_gl_acct), '')
    WHERE
        p.dt_load = @recdate
""").createOrReplaceTempView("updated_rec_pl_3way_mtd_posting_sum")

# The 'updated_rec_pl_3way_mtd_posting_sum' view will have the 'instrmnt_type' column updated where conditions are met.
